JOB=1483828 ARRAY=0 HOST=node16
Fri Jan 23 19:19:06 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     On  |   00000000:48:00.0 Off |                    0 |
|  0%   28C    P0             52W /  300W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/usr/prakt/w0012/miniconda3/envs/tridi/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  _C._set_float32_matmul_precision(precision)
2026-01-23 19:19:24 - INFO - tridi.utils.exp - Initializing wandb...
2026-01-23 19:19:24 - INFO - tridi.utils.exp - Trying to initialize WANDB try 0
wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
wandb: Currently logged in as: c-yang (yaoweiwang-technical-university-of-munich) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run w3tzj7xm
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /usr/prakt/w0012/HH_gen/experiments/000_chi3d/wandb/run-20260123_191925-w3tzj7xm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 000_chi3d
wandb: ‚≠êÔ∏è View project at https://wandb.ai/yaoweiwang-technical-university-of-munich/hhgen
wandb: üöÄ View run at https://wandb.ai/yaoweiwang-technical-university-of-munich/hhgen/runs/w3tzj7xm
2026-01-23 19:19:38 - INFO - tridi.utils.exp - Trying to initialize WANDB try 1
wandb: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
2026-01-23 19:19:39 - INFO - tridi.utils.exp - Initialized WANDB
2026-01-23 19:19:39 - INFO - tridi.utils.training - Seeding node 0 with seed 42
2026-01-23 19:19:39 - INFO - tridi.model - Created model: transformer_unidiffuser_3 with 14.9M trainable params (14.9M total).
2026-01-23 19:19:40 - INFO - tridi.utils.training - lr = 0.00015 (absolute learning rate)
2026-01-23 19:19:41 - INFO - tridi.utils.training - Loading checkpoint from /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0020000.pth
2026-01-23 19:19:42 - INFO - tridi.utils.training - Loaded model checkpoint from /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0020000.pth
2026-01-23 19:19:42 - INFO - tridi.utils.training - Loaded optimizer from checkpoint
2026-01-23 19:19:42 - INFO - tridi.utils.training - Loaded scheduler from checkpoint
2026-01-23 19:19:42 - INFO - tridi.utils.training - Resumed state from checkpoint: step 20000, epoch 1000
2026-01-23 19:19:42 - INFO - tridi.utils.training - Finished loading checkpoint
2026-01-23 19:19:42 - INFO - tridi.data.hh_dataset - HHDataset chi3d: loading from data/preprocessed/chi3d_smplx/dataset_train_25fps.hdf5.
2026-01-23 19:19:42 - INFO - tridi.data.hh_dataset - HH dataset chi3d train has 19768 frames (skipped_missing_seq=0).
2026-01-23 19:19:42 - INFO - tridi.data.hh_dataset - HHDataset chi3d: split=train #frames=19768
2026-01-23 19:19:42 - INFO - tridi.data.hh_dataset - HHDataset chi3d: loading from data/preprocessed/chi3d_smplx/dataset_val_25fps.hdf5.
2026-01-23 19:19:45 - INFO - tridi.data.hh_dataset - HH dataset chi3d val has 5548 frames (skipped_missing_seq=0).
2026-01-23 19:19:45 - INFO - tridi.data.hh_dataset - HHDataset chi3d: split=val #frames=5548
2026-01-23 19:19:45 - INFO - tridi.data - Train data length: 19768
2026-01-23 19:19:45 - INFO - tridi.data - Val data length: 5548
2026-01-23 19:19:47 - INFO - tridi.core.trainer - ***** Starting training *****
    Dataset train size: 19_768
    Dataset val size: 5_548
    Dataloader train size: 20
    Dataloader val size: 6
    Batch size per device = 1024
    Total train batch size (w. parallel, dist & accum) = 1024
    Gradient Accumulation steps = 1
    Max training steps = 300000
    Training state = TrainState(epoch=1000, step=20000, initial_step=20000)
log_dir: /usr/prakt/w0012/HH_gen/experiments/000_chi3d
cfg.resume.checkpoint: /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0020000.pth
2026-01-23 21:07:15 - INFO - tridi.core.trainer - Saved checkpoint to /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0025000.pth
2026-01-23 22:55:59 - INFO - tridi.core.trainer - Saved checkpoint to /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0030000.pth
2026-01-24 00:47:30 - INFO - tridi.core.trainer - Saved checkpoint to /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0035000.pth
2026-01-24 02:44:10 - INFO - tridi.core.trainer - Saved checkpoint to /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0040000.pth
[2026-01-24T03:19:11.014] error: *** JOB 1483828 ON node16 CANCELLED AT 2026-01-24T03:19:11 DUE TO TIME LIMIT ***
