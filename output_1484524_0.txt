JOB=1484525 ARRAY=0 HOST=node9
Sun Jan 25 10:30:54 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Quadro RTX 6000                On  |   00000000:1B:00.0 Off |                  Off |
| 33%   29C    P8              6W /  260W |       0MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/usr/prakt/w0012/miniconda3/envs/tridi/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  _C._set_float32_matmul_precision(precision)
2026-01-25 10:32:49 - INFO - tridi.utils.exp - Initializing wandb...
2026-01-25 10:32:49 - INFO - tridi.utils.exp - Trying to initialize WANDB try 0
wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
wandb: Currently logged in as: c-yang (yaoweiwang-technical-university-of-munich) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run jjpnfuxc
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /usr/prakt/w0012/HH_gen/experiments/000_chi3d/wandb/run-20260125_103250-jjpnfuxc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 000_chi3d
wandb: ‚≠êÔ∏è View project at https://wandb.ai/yaoweiwang-technical-university-of-munich/hhgen
wandb: üöÄ View run at https://wandb.ai/yaoweiwang-technical-university-of-munich/hhgen/runs/jjpnfuxc
2026-01-25 10:32:55 - INFO - tridi.utils.exp - Trying to initialize WANDB try 1
wandb: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
2026-01-25 10:32:56 - INFO - tridi.utils.exp - Initialized WANDB
2026-01-25 10:32:57 - INFO - tridi.utils.training - Seeding node 0 with seed 42
2026-01-25 10:32:57 - INFO - tridi.model - Created model: transformer_unidiffuser_3 with 14.9M trainable params (14.9M total).
2026-01-25 10:32:58 - INFO - tridi.utils.training - lr = 0.00015 (absolute learning rate)
2026-01-25 10:32:59 - INFO - tridi.utils.training - Loading checkpoint from /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0040000.pth
2026-01-25 10:33:00 - INFO - tridi.utils.training - Loaded model checkpoint from /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0040000.pth
2026-01-25 10:33:00 - INFO - tridi.utils.training - Loaded optimizer from checkpoint
2026-01-25 10:33:00 - INFO - tridi.utils.training - Loaded scheduler from checkpoint
2026-01-25 10:33:00 - INFO - tridi.utils.training - Resumed state from checkpoint: step 40000, epoch 2000
2026-01-25 10:33:00 - INFO - tridi.utils.training - Finished loading checkpoint
2026-01-25 10:33:00 - INFO - tridi.data.hh_dataset - HHDataset chi3d: loading from data/preprocessed/chi3d_smplx/dataset_train_25fps.hdf5.
2026-01-25 10:33:09 - INFO - tridi.data.hh_dataset - HH dataset chi3d train has 19768 frames (skipped_missing_seq=0).
2026-01-25 10:33:09 - INFO - tridi.data.hh_dataset - HHDataset chi3d: split=train #frames=19768
2026-01-25 10:33:09 - INFO - tridi.data.hh_dataset - HHDataset chi3d: loading from data/preprocessed/chi3d_smplx/dataset_val_25fps.hdf5.
2026-01-25 10:33:11 - INFO - tridi.data.hh_dataset - HH dataset chi3d val has 5548 frames (skipped_missing_seq=0).
2026-01-25 10:33:11 - INFO - tridi.data.hh_dataset - HHDataset chi3d: split=val #frames=5548
2026-01-25 10:33:11 - INFO - tridi.data - Train data length: 19768
2026-01-25 10:33:11 - INFO - tridi.data - Val data length: 5548
2026-01-25 10:33:14 - INFO - tridi.core.trainer - ***** Starting training *****
    Dataset train size: 19_768
    Dataset val size: 5_548
    Dataloader train size: 20
    Dataloader val size: 6
    Batch size per device = 1024
    Total train batch size (w. parallel, dist & accum) = 1024
    Gradient Accumulation steps = 1
    Max training steps = 300000
    Training state = TrainState(epoch=2000, step=40000, initial_step=40000)
log_dir: /usr/prakt/w0012/HH_gen/experiments/000_chi3d
cfg.resume.checkpoint: /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0040000.pth
2026-01-25 12:24:06 - INFO - tridi.core.trainer - Saved checkpoint to /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0045000.pth
2026-01-25 14:14:37 - INFO - tridi.core.trainer - Saved checkpoint to /usr/prakt/w0012/HH_gen/experiments/000_chi3d/checkpoints/checkpoint-step-0050000.pth
[2026-01-25T14:39:14.289] error: *** JOB 1484525 ON node9 CANCELLED AT 2026-01-25T14:39:14 DUE to SIGNAL Terminated ***
